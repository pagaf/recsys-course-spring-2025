{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "** Я использовал 2 подхода**\n",
    "\n",
    "1. **Первый подход: обогащение выборки c помощью Negative Sampling**  \n",
    "   В этом методе мы взяли исходные пары «контекст → следующий трек» и дополнили их случайными негативными примерами, пометив их время прослушивания как 0.  \n",
    "   Для каждого контекста удаляли реальные положительные треки и из оставшегося множества выбирали до 10 случайных треков, что увеличивало обучающую выборку на ~50 000 записей.  \n",
    "   Полученные пары (контекст, негативный трек, 0.0) объединялись с исходными, и на этом датасете обучались новые эмбеддинги для треков и контекстов.  \n",
    "   Попытки кластеризации эмбеддингов и отбора негативных треков из разных кластеров тоже не дали устойчивого прироста качества.\n",
    "\n",
    "2. **Второй подход: конкатенация эмбеддингов артистов и треков**  \n",
    "   Здесь к эмбеддингам контекста и кандидата добавляются эмбеддинги соответствующих артистов, что позволяет модели учитывать предпочтения не только по трекам, но и по исполнителям.  \n",
    "   В архитектуре `ContextualRec` четыре эмбеддинга (контекст-трек, кандидат-трек, контекст-артист, кандидат-артист) объединяются и пропускаются через два полносвязных слоя с активацией ReLU.  \n",
    "   Такая модификация позволила модели лучше различать ситуации, когда слушатель привязан к артисту, а не к конкретному треку.  \n",
    "   Данный подход оказался более эффективным и лёгко масштабируемым за счёт небольшой добавочной размерности артиста.  "
   ],
   "metadata": {
    "id": "3PCsqTvQ7YAD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7rRsL4P3Xb8E",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d70fbd2e-d174-4205-f689-c2f80e2d00c1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.2)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.13.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.15)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.1/823.1 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m67.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m59.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m31.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m8.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m76.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m961.5/961.5 kB\u001B[0m \u001B[31m40.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_lightning-2.5.1.post0 torchmetrics-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "id": "PgBzKtKBY4dh"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open('data.json','r') as f:\n",
    "    interactions = pd.read_json(f, lines=True)\n",
    "with open('tracks.json','r') as f:\n",
    "    track_meta = pd.read_json(f, lines=True)"
   ],
   "metadata": {
    "id": "1Bcvv-pd3NXi"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import namedtuple\n",
    "Pair = namedtuple('Pair',['user','start','track','time','latency','recommendation','experiments'])\n",
    "def get_pairs(df_user):\n",
    "    lst=[]\n",
    "    first=None\n",
    "    for _,r in df_user.sort_values('timestamp').iterrows():\n",
    "        if first is None:\n",
    "            first=r['track']\n",
    "        else:\n",
    "            lst.append((r['user'], first, r['track'], r['time']))\n",
    "        if r['message']=='last':\n",
    "            first=None\n",
    "    return pd.DataFrame(lst, columns=['user','start','track','time'])\n",
    "\n",
    "pairs = interactions.groupby('user').apply(get_pairs).reset_index(drop=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tuBn82S4WBH",
    "outputId": "ca84be9e-df3b-4223-a40d-ad73176253b4"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-48c16da22098>:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  pairs = interactions.groupby('user').apply(get_pairs).reset_index(drop=True)\n",
      "<ipython-input-7-48c16da22098>:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pairs = interactions.groupby('user').apply(get_pairs).reset_index(drop=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_track = LabelEncoder().fit(track_meta.track)\n",
    "encoder_artist = LabelEncoder().fit(track_meta.artist)\n",
    "\n",
    "pairs['start_idx'] = encoder_track.transform(pairs.start)\n",
    "pairs['track_idx'] = encoder_track.transform(pairs.track)\n",
    "track_meta['track_idx'] = encoder_track.transform(track_meta.track)\n",
    "track_meta['artist_idx'] = encoder_artist.transform(track_meta.artist)\n",
    "\n",
    "pairs = pairs.merge(track_meta[['track_idx','artist_idx']].rename(\n",
    "    columns={'track_idx':'start_idx','artist_idx':'artist_start_idx'}), on='start_idx')\n",
    "# track artist:\n",
    "track_meta = track_meta.rename(columns={'artist_idx':'artist_track_idx'})\n",
    "pairs = pairs.merge(track_meta[['track_idx','artist_track_idx']].rename(\n",
    "    columns={'track_idx':'track_idx'}), on='track_idx')\n"
   ],
   "metadata": {
    "id": "BrNvXC8l45gS"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ContextualRec(nn.Module):\n",
    "    def __init__(self, n_tracks, n_artists, emb_dim=64, art_emb_dim=32):\n",
    "        super().__init__()\n",
    "        self.track_emb = nn.Embedding(n_tracks, emb_dim)\n",
    "        self.artist_emb = nn.Embedding(n_artists, art_emb_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim*2 + art_emb_dim*2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, ctx, tr, art_ctx, art_tr):\n",
    "        e1=self.track_emb(ctx); e2=self.track_emb(tr)\n",
    "        a1=self.artist_emb(art_ctx); a2=self.artist_emb(art_tr)\n",
    "        x=torch.cat([e1,e2,a1,a2],dim=1)\n",
    "        return self.fc(x).squeeze()\n"
   ],
   "metadata": {
    "id": "KBSY_oOi49JQ"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.ctx = torch.LongTensor(df.start_idx.values)\n",
    "        self.tr = torch.LongTensor(df.track_idx.values)\n",
    "        self.ac = torch.LongTensor(df.artist_start_idx.values)\n",
    "        self.at = torch.LongTensor(df.artist_track_idx.values)\n",
    "        self.y = torch.FloatTensor(df.time.values)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self,i): return self.ctx[i],self.tr[i],self.ac[i],self.at[i],self.y[i]\n",
    "\n",
    "mask = np.random.rand(len(pairs))\n",
    "train_df = pairs[mask<0.8]; val_df = pairs[(mask>=0.8)&(mask<0.9)]; test_df = pairs[mask>=0.9]\n",
    "train_loader = DataLoader(PairDataset(train_df), batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(PairDataset(val_df), batch_size=1024)\n",
    "test_loader = DataLoader(PairDataset(test_df), batch_size=1024)"
   ],
   "metadata": {
    "id": "EfeH8f4Z5Hh2"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ContextualRec(\n",
    "    n_tracks=len(encoder_track.classes_),\n",
    "    n_artists=len(encoder_artist.classes_)\n",
    ").to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "for epoch in range(10):\n",
    "    model.train(); total=0\n",
    "    for ctx,tr,ac,at,y in train_loader:\n",
    "        ctx,tr,ac,at,y=[x.to(DEVICE) for x in (ctx,tr,ac,at,y)]\n",
    "        opt.zero_grad(); pred=model(ctx,tr,ac,at)\n",
    "        loss=loss_fn(pred,y); loss.backward(); opt.step()\n",
    "        total+=loss.item()\n",
    "    print(f\"Epoch {epoch+1} loss {total/len(train_loader):.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYCHLPpF5MaC",
    "outputId": "844e00de-6688-42c9-9cc8-ea193b2de100"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 loss 0.1635\n",
      "Epoch 2 loss 0.1418\n",
      "Epoch 3 loss 0.1343\n",
      "Epoch 4 loss 0.1278\n",
      "Epoch 5 loss 0.1219\n",
      "Epoch 6 loss 0.1147\n",
      "Epoch 7 loss 0.1071\n",
      "Epoch 8 loss 0.0994\n",
      "Epoch 9 loss 0.0911\n",
      "Epoch 10 loss 0.0826\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output_file = 'recs_ab.json'\n",
    "with open(output_file,'w') as fout:\n",
    "    for _,row in test_df.iterrows():\n",
    "        ctx = torch.LongTensor([row.start_idx]).to(DEVICE)\n",
    "        art_ctx = torch.LongTensor([row.artist_start_idx]).to(DEVICE)\n",
    "        all_tr = torch.arange(len(encoder_track.classes_)).to(DEVICE)\n",
    "        all_art = torch.LongTensor(track_meta.artist_track_idx.values).to(DEVICE)\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            scores = model(ctx.repeat(len(all_tr)), all_tr, art_ctx.repeat(len(all_tr)), all_art)\n",
    "        latency = time.time() - start_time\n",
    "        rec = encoder_track.inverse_transform([scores.argmax().cpu().item()])[0]\n",
    "        entry = {\n",
    "            \"user\": int(row.user),\n",
    "            \"track\": int(row.track),\n",
    "            \"time\": float(row.time),\n",
    "            \"latency\": float(latency),\n",
    "            \"recommendation\": int(rec),\n",
    "            \"experiments\": {\"ALL\": \"T4\"}\n",
    "        }\n",
    "        fout.write(json.dumps(entry) + \"\\n\")\n",
    "print(f\"Saved {output_file}\")"
   ],
   "metadata": {
    "id": "1ugxUhsK5T_i",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22cabac7-e655-4ead-c5e9-324cfa55879f"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved recs_ab.json\n"
     ]
    }
   ]
  }
 ]
}
